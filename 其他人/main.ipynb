{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "import lightgbm as lgb \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_table('ijcai_train_final.txt',sep=' ')\n",
    "data_test = pd.read_table('ijcai_test_final.txt',sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.基于time的特征提取（一次构建）\n",
    "\n",
    "def MeanVarFeature(data,co,Ftype,time):\n",
    "    if Ftype == 'mean':\n",
    "        MVF = data.groupby(co)[time].mean().reset_index()\n",
    "        MVF.columns = [co, '{}_mean_{}'.format(co[:-3],time)]\n",
    "        data = data.merge(MVF, how='left', on=co)\n",
    "    elif Ftype == 'var':\n",
    "        MVF = data.groupby(co)[time].std().reset_index()\n",
    "        MVF.columns = [co, '{}_var_{}'.format(co[:-3],time)]\n",
    "        data = data.merge(MVF, how='left', on=co)\n",
    "    return data\n",
    "\n",
    "def MeanVarDoubleFeature(data,co,Ftype,time1='date',time2='hour'):\n",
    "    if Ftype == 'mean':\n",
    "        MVF = data.groupby([co,time1])[time2].mean().reset_index()\n",
    "        MVF.columns = [co,time1, '{}_mean_{}_{}'.format(co[:-3],time1,time2)]\n",
    "        data = data.merge(MVF, how='left', on=[co,time1])\n",
    "        \n",
    "    if Ftype == 'var':\n",
    "        MVF = data.groupby([co,time1])[time2].var().reset_index()\n",
    "        MVF.columns = [co,time1, '{}_var_{}_{}'.format(co[:-3],time1,time2)]\n",
    "        data = data.merge(MVF, how='left', on=[co,time1])\n",
    "        \n",
    "    return data\n",
    "\n",
    "def TimeFeaturePick(data):\n",
    "    data = data.copy()\n",
    "    data['time'] = data['context_timestamp'].apply(lambda x:datetime.datetime.fromtimestamp(x)) #localtime - 标准时间\n",
    "    data['date'] = data['time'].apply(lambda x:x.day).astype('int')\n",
    "    data['hour'] = data['time'].apply(lambda x:x.hour).astype('int')\n",
    "    data['minute'] = data['time'].apply(lambda x:x.minute).astype('int')\n",
    "    \n",
    "    for co in id_columns:\n",
    "        for Ftype in ['mean','var']:\n",
    "            for time in ['date','hour']:\n",
    "                data = MeanVarFeature(data,co,Ftype,time)\n",
    "            data = MeanVarDoubleFeature(data,co,Ftype)\n",
    "    return data\n",
    "\n",
    "dt = TimeFeaturePick(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2.基于点击者user的特征提取（二次构建）\n",
    "\n",
    "def UserFeature(dt):\n",
    "    dt = dt.copy()    \n",
    "    \n",
    "    #1.1 基于click的user特征\n",
    "    dt['user_first_click_time'] = dt['context_timestamp'].min()  #第一次点击的时间\n",
    "    dt['user_last_click_time'] = dt['context_timestamp'].max()   #最后一次点击的时间\n",
    "    dt['user_last-first_time'] = dt['user_first_click_time'] - dt['user_last_click_time'] #首尾时间差\n",
    "    dt['user_count'] = len(dt)  #总点击次数，反映用户活跃度\n",
    "    dt['user_shop_count'] = len(set(dt['shop_id']))  #用户点击的不同shop总数\n",
    "    dt['user_item_count'] = len(set(dt['item_id']))  #用户点击的不同item总数\n",
    "    \n",
    "    #1.2 基于画像的user特征\n",
    "    #1.2.1  提取id类列做交互，得到该user最常点击的id类型\n",
    "    for co in id_columns:  #得到用户最常点击的id\n",
    "        dt['user_mode_{}'.format(co)] = dt[co].mode()[0]\n",
    "    #1.2.2  提取level类列做交互，得到该user的各项level特征\n",
    "    for co in level_columns:  \n",
    "        dt['user_mean_{}'.format(co)] = dt[co].mean() #得到用户各项level列的均值偏好\n",
    "        dt['user_var_{}'.format(co)] = dt[co].var() #得到用户各项level列的方差偏好\n",
    "        dt['user_max_{}'.format(co)] = dt[co].max() #得到用户各项level列的方差偏好\n",
    "        dt['user_min_{}'.format(co)] = dt[co].min() #得到用户各项level列的方差偏好\n",
    "        \n",
    "    return dt\n",
    "\n",
    "dt = dt.groupby('user_id').apply(UserFeature).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3.基于点击对象item的特征提取（三次构建）\n",
    "\n",
    "def ItemFeature(dt):\n",
    "    dt = dt.copy()\n",
    "    describe_columns = ([x for x in dt.columns if 'mean' in x or 'var' in x or 'user_max' in x or 'user_min' in x])\n",
    "    \n",
    "    max_time = dt['context_timestamp'].max()\n",
    "    last_day_time = max_time - 86400\n",
    "\n",
    "    #2.1 基于画像的item特征\n",
    "    dt['item_count'] = len(dt) #item被点击总次数，反映item热度\n",
    "    dt['item_user_count'] = len(set(dt['user_id'])) #点入item的用户总数，反映shop热度\n",
    "    dt['item_normal_price_level'] = dt[dt['context_timestamp']<=last_day_time]['item_price_level'].mean() #平时价格\n",
    "    dt['item_abnormal_price_level'] = dt[dt['context_timestamp']>last_day_time]['item_price_level'].mean() #异常时价格\n",
    "    dt['abnormal_discount'] = dt['item_normal_price_level'] / dt['item_abnormal_price_level'] #异常时折扣\n",
    "    \n",
    "    #2.2 基于item和user再交互的特征\n",
    "    for co in id_columns:  #得到该shop对不同的user最常点击ID的偏好\n",
    "        dt['item_user_mode_{}'.format(co)] = dt['user_mode_{}'.format(co)].mode()[0]\n",
    "        \n",
    "    for co in level_columns+describe_columns :  #得到该item对不同的user属性的统计特征偏好\n",
    "        dt['item_user_mean_{}'.format(co)] = dt[co].mean()  #二次交互均值特征\n",
    "        dt['item_user_var_{}'.format(co)] = dt[co].var()  #二次交互方差特征\n",
    "        dt['item_user_max_{}'.format(co)] = dt[co].max()  #二次交互最大值特征\n",
    "        dt['item_user_min_{}'.format(co)] = dt[co].min()  #二次交互最小值特征    \n",
    "\n",
    "    return dt\n",
    "\n",
    "dt = dt.groupby('item_id').apply(ItemFeature).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FeaturePick(dt):\n",
    "    list_columns = [x for x in dt.columns if 'list' in x]   #筛选list类列，用于拆分并交互\n",
    "\n",
    "    for co in list_columns:\n",
    "        dt['{}_len'.format(co)] = dt[co].apply(lambda x:len(x.split(';')))\n",
    "        dt['{}_id0'.format(co)] = dt[co].apply(lambda x:x.split(';')[0])\n",
    "        dt['{}_id1'.format(co)] = dt[co].apply(lambda x:x.split(';')[1])\n",
    "        del dt[co]\n",
    "    dt['len_predict_category_property'] = dt['predict_category_property'].apply(lambda x:len(x.split(';')))\n",
    "    dt['predict_category_id0'] = dt['predict_category_property'].apply(lambda x:x.split(';')[0].split(':')[0])\n",
    "    dt['predict_property_id0'] = dt['predict_category_property'].apply(lambda x:x.split(';')[0].split(':')[1])\n",
    "    del dt['predict_category_property']\n",
    "\n",
    "    #0.2按列的类型分组\n",
    "    id_columns = [x for x in dt.columns if 'id' in x]  #筛选id类列，用于交互（得到用户点击最多的ID）\n",
    "    level_columns = [x for x in dt.columns if 'level' in x]  #筛选level类列，用于交互（得到用户的各项均值偏好）\n",
    "    \n",
    "    dt = TimeFeaturePick(dt)\n",
    "    dt = dt.groupby('user_id').apply(UserFeature).reset_index(drop=True)\n",
    "    dt = dt.groupby('item_id').apply(ItemFeature).reset_index(drop=True)\n",
    "    del dt['time']\n",
    "    return dt\n",
    "\n",
    "data_train = FeaturePick(data_train)\n",
    "data_test  = FeaturePick(data_test)\n",
    "\n",
    "#经过特征工程处理，共得到752维特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分训练集测试集\n",
    "train_feature = data_train.copy()\n",
    "train_label = data_train['is_trade']\n",
    "test_feature = data_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型训练\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "# import DeepFM\n",
    "\n",
    "# lgb\n",
    "lgb_train = lgb.LGBMClassifier(num_leaves=1024, learning_rate=0.01,n_estimators=4200,colsample_bytree = 0.8,\n",
    "                    subsample = 0.8)\n",
    "lgb_train.fit(train_feature,train_label)\n",
    "lgb_pre_test_y = lgb_train.predict_proba(test_feature)[:,1]\n",
    "\n",
    "# xgb\n",
    "xgb_train = xgb.XGBClassifier(max_depth=10,learning_rate=0.01,n_estimators=4000,colsample_bylevel=0.5,colsample_bytree=0.8,subsample=0.8)\n",
    "xgb_train.fit(train_feature,train_label)\n",
    "xgb_pre_test_y = xgb_train.predict_proba(test_feature)[:,1]\n",
    "\n",
    "# NN\n",
    "DeepFM_train = DeepFM(learning_rate = 0.0001,drop_out=True,batch_size = 32*16, h_depth = 4)\n",
    "DeepFM_train.fit(train_feature,train_label)\n",
    "nn_pre_test_y = DeepFM_train.predict_proba(test_feature)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#答案输出\n",
    "ans = lgb_pre_test_y*0.6+xgb_pre_test_y*0.2+nn_pre_test_y*0.2\n",
    "submit = DF()\n",
    "submit['instance_id'] = data_test['instance_id'] \n",
    "submit['predicted_score'] = ans\n",
    "submit.to_csv('ans.txt',sep=' ',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
